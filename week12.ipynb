{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16df3d39-9737-43a9-85ff-458105f513a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1(a) P(A | Defective) = 0.3871\n",
      "1(b) P(C | Not Defective) = 0.2514\n",
      "3(a) Entropy of X: 2.3219\n",
      "3(a) Entropy of Y: 2.0464\n",
      "3(b) X has higher entropy because its distribution is more even.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Bayes' Theorem\n",
    "# ---------------------------\n",
    "\n",
    "# Probabilities for each process\n",
    "p_A = 0.4\n",
    "p_B = 0.35\n",
    "p_C = 0.25\n",
    "\n",
    "# Defective rates by process\n",
    "p_D_given_A = 0.015\n",
    "p_D_given_B = 0.02\n",
    "p_D_given_C = 0.01\n",
    "\n",
    "# (a) P(A | Defective)\n",
    "# First, calculate total defective probability\n",
    "p_D = p_D_given_A * p_A + p_D_given_B * p_B + p_D_given_C * p_C\n",
    "\n",
    "# Then apply Bayes' Theorem\n",
    "p_A_given_D = (p_D_given_A * p_A) / p_D\n",
    "print(\"1(a) P(A | Defective) =\", round(p_A_given_D, 4))\n",
    "\n",
    "# (b) P(C | Not Defective)\n",
    "# First, total probability of not being defective\n",
    "p_notD = (1 - p_D_given_A) * p_A + (1 - p_D_given_B) * p_B + (1 - p_D_given_C) * p_C\n",
    "\n",
    "# Then use Bayes' Theorem again\n",
    "p_C_given_notD = ((1 - p_D_given_C) * p_C) / p_notD\n",
    "print(\"1(b) P(C | Not Defective) =\", round(p_C_given_notD, 4))\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Entropy Function\n",
    "# ---------------------------\n",
    "\n",
    "def entropy(probs):\n",
    "    p = np.array(probs)\n",
    "    p = p[p > 0]  # remove zero probabilities\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Entropy Calculations\n",
    "# ---------------------------\n",
    "\n",
    "# Probabilities for X (uniform) and Y (skewed)\n",
    "p_X = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "p_Y = [0.1, 0.4, 0.1, 0.3, 0.1]\n",
    "\n",
    "# Entropy results\n",
    "H_X = entropy(p_X)\n",
    "H_Y = entropy(p_Y)\n",
    "\n",
    "print(\"3(a) Entropy of X:\", round(H_X, 4))\n",
    "print(\"3(a) Entropy of Y:\", round(H_Y, 4))\n",
    "\n",
    "# (b) Explanation of difference\n",
    "if H_X > H_Y:\n",
    "    print(\"3(b) X has higher entropy because its distribution is more even.\")\n",
    "else:\n",
    "    print(\"3(b) Y has higher entropy due to more unpredictability in outcomes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d93eb-9827-4686-bc56-21df669080bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
